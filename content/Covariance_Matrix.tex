\section{Covariance Matrix}
Let $X$  be a random vector of dimension $d \times 1$ with expectation $\mu _{X}$. 

Matrix outer products!\\ 

$\Sigma =\mathbb E[(X- \mu _{X})(X- \mu _{X})^ T] \\= \mathbb {E}[XX^ T] - \mathbb {E}[X]\mathbb {E}[X]^ T
\\= \mathbb {E}[XX^ T] - \mu _{X}\mu _{X}^ T$

% Reusing this file to add my notes

\section {GLM one parameter}

% Vector variables (in Bold Font style)
\newcommand{\va}{\mathbf{a}} \newcommand{\vb}{\mathbf{b}} \newcommand{\vc}{\mathbf{c}} \newcommand{\vd}{\mathbf{d}} \newcommand{\ve}{\mathbf{e}} \newcommand{\vf}{\mathbf{f}} \newcommand{\vg}{\mathbf{g}} \newcommand{\vh}{\mathbf{h}} \newcommand{\vi}{\mathbf{i}} \newcommand
{\vj}{\mathbf{j}} \newcommand{\vk}{\mathbf{k}} \newcommand{\vl}{\mathbf{l}} \newcommand{\vm}{\mathbf{m}} \newcommand{\vn}{\mathbf{n}} \newcommand{\vo}{\mathbf{o}} \newcommand{\vp}{\mathbf{p}} \newcommand{\vq}{\mathbf{q}} \newcommand{\vr}{\mathbf{r}} \newcommand{\vs}{\math
bf{s}} \newcommand{\vt}{\mathbf{t}} \newcommand{\vu}{\mathbf{u}} \newcommand{\vv}{\mathbf{v}} \newcommand{\vw}{\mathbf{w}} \newcommand{\vx}{\mathbf{x}} \newcommand{\vy}{\mathbf{y}} \newcommand{\vz}{\mathbf{z}} 
\newcommand{\vA}{\mathbf{A}} \newcommand{\vB}{\mathbf{B}} \newcommand{\vC}{\mathbf{C}} \newcommand{\vD}{\mathbf{D}} \newcommand{\vE}{\mathbf{E}} \newcommand{\vF}{\mathbf{F}} \newcommand{\vG}{\mathbf{G}} \newcommand{\vH}{\mathbf{H}} \newcommand{\vI}{\mathbf{I}} \newcommand{\vJ}{\mathbf{J}} \newcommand{\vK}{\mathbf{K}} \newcommand{\vL}{\mathbf{L}} \newcommand{\vM}{\mathbf{M}} \newcommand{\vN}{\mathbf{N}} \newcommand{\vO}{\mathbf{O}} \newcommand{\vP}{\mathbf{P}} \newcommand{\vQ}{\mathbf{Q}} \newcommand{\vR}{\mathbf{R}} \newcommand{\vS}{\mathbf{S}} \newcommand{\vT}{\mathbf{T}} \newcommand{\vU}{\mathbf{U}} \newcommand{\vV}{\mathbf{V}} \newcommand{\vW}{\mathbf{W}} \newcommand{\vX}{\mathbf{X}} \newcommand{\vY}{\mathbf{Y}} \newcommand{\vZ}{\mathbf{Z}} 

% Greek Vector variables (in Bold Font style)
\newcommand{\vbeta}{\bm{\beta}} 
\newcommand{\vbhat}{\bm{\hat \beta}}
\newcommand{\vbstar}{\bm{\beta^*}}
\newcommand{\veps}{\bm{\epsilon}}
\newcommand{\vmu}{\bm{\mu}}
\newcommand{\vtheta}{\bm{\theta}}
\newcommand{\valpha}{\bm{\alpha}}
\newcommand{\vdelta}{\bm{\delta}}

% Constant vectors
\newcommand{\vzero}{\mathbf{0}}
\newcommand{\vone}{\mathbf{1}}
\newcommand{\thetac}{\mathrm{\theta^{(0)}}}

% Scalars

% Matrix variables (in DS style where possible)
\newcommand{\mA}{\mathds{A}} \newcommand{\mB}{\mathds{B}} \newcommand{\mC}{\mathds{C}} \newcommand{\mD}{\mathds{D}} \newcommand{\mE}{\mathds{E}} \newcommand{\mF}{\mathds{F}} \newcommand{\mG}{\mathds{G}} \newcommand{\mH}{\mathds{H}} \newcommand{\mI}{\mathds{I}} \newcommand{\mJ}{\mathds{J}} \newcommand{\mK}{\mathds{K}} \newcommand{\mL}{\mathds{L}} \newcommand{\mM}{\mathds{M}} \newcommand{\mN}{\mathds{N}} \newcommand{\mO}{\mathds{O}} \newcommand{\mP}{\mathds{P}} \newcommand{\mQ}{\mathds{Q}} \newcommand{\mR}{\mathds{R}} \newcommand{\mS}{\mathds{S}} \newcommand{\mT}{\mathds{T}} \newcommand{\mU}{\mathds{U}} \newcommand{\mV}{\mathds{V}} \newcommand{\mW}{\mathds{W}} \newcommand{\mX}{\mathds{X}} \newcommand{\mY}{\mathds{Y}} \newcommand{\mZ}{\mathds{Z}}

% Greek matrix variables
\newcommand{\msigma}{\Sigma}
\newcommand{\mbeta}{\mathds{B}}

\newcommand{\argmax}{\mathop{\mathrm{argmax}}}
\newcommand{\argmin}{\mathop{\mathrm{argmin}}}


\begin {equation} \begin {split} 
& f_\theta(y) = \exp (\frac {y \theta - b(\theta)} {\phi} + c(y, \phi)) \\
& b(), c() \text { are known. $\phi$ is called the dispersion parameter} \\
\end {split} \end {equation}

\begin {equation} \begin {split} 
& f_\theta(y) = \exp (\frac {y \theta - b(\theta)} {\phi} + c(y, \phi)) \\
& b(), c() \text { are known. $\phi$ is called the dispersion parameter} \\
\end {split} \end {equation}

A canonical link function forces:
\begin {equation} \begin {split}
& g(\mu) = \theta \\
& \therefore \mu = g^{-1}(\theta) \\
& \implies g^{-1}(\theta) =  b^{'}(\theta) \\
& \implies g = b{'}^{-1} \\
\end {split} \end {equation}

The log-likelihood is:
\begin {equation} \begin {split} 
l_n(\vY, \mX, \vbeta) = \frac { \sum \limits_{i=1}^{n} Y_i \vX_i^T \vbeta -b(\vX_i^T \vbeta) } {\phi}  + \sum \limits_{i=1}^{n} c(Y_i, \phi) \\
\end {split} \end {equation}

$\vbeta$ can be estimated as:
\begin {equation} \begin {split}
& \hat \vbeta = \argmax_{\vbeta} (l_n(\vY, \mX, \vbeta)) \\
\end {split} \end {equation}

 Distribution | $b(\theta)$ | $g(\mu)$ \\
 Gaussian | $ \frac {\theta^2} {2}$ | $ \mu $ \\
 Poisson | $ e^{\theta} $ | $ \ln(\mu) $ \\
 Bernoulli | $ \ln (1 + e^{\theta}) $ | $ \ln (\frac {\mu} {1 - \mu}) $ \\
 Gamma | $ -\ln (-\theta) $ | $ \frac {-1} {\mu} $ \\
